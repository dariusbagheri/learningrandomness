import numpy as np
from sklearn.neural_network import MLPRegressor
import matplotlib.pyplot as plt
import random

from sklearn.preprocessing import StandardScaler

%matplotlib inline



# Number of tries for the experiment
expnumb = 2003
tries= np.array([],int)
chosens = np.array([],int)
smallers = np.array([],int)
biggers = np.array([],int)
two_d_arr = np.array([4,expnumb])


percent_training = 0.9
num_training = int(0.9*expnumb)
num_test = expnumb - num_training

for x in range(1,expnumb): 
  
    chosen = random.randint(1,1000)
    start = 500
    guess = np.array([1,1000,start])
    sm = 0
    bg = 0
    #number of guesses  
    for i in range(2,101):
        try:
            if guess[i] > chosen:        

                sm += 1
                hehe = np.sort(guess)
                #print('smaller', guess, hehe, chosen, i)

                last = np.where(hehe == guess[i])
                if hehe[last[0][0]-1]+1 != hehe[last[0][0]]:

                    guess = np.append(hehe, random.randint(hehe[last[0][0]-1]+1, hehe[last[0][0]]))
            elif guess[i] < chosen:

                bg +=1
                hehe = np.sort(guess)
                #print('bigger', guess, hehe, chosen, i)

                last = np.where(hehe == guess[i])
                if hehe[last[0][0]]+1 != hehe[last[0][0]+1]:

                    guess = np.append(hehe, random.randint(hehe[last[0][0]]+1, hehe[last[0][0]+1]))
            elif guess[i] == chosen:
                #print(" )

                tries = np.append(tries, i)
                chosens = np.append(chosens, chosen)
                smallers = np.append(smallers, sm)
                biggers = np.append(biggers,bg)
                break
        except:
            continue
        
      
        
        
          
feat_d_arr = np.vstack([[smallers[0:expnumb,]],[biggers[0:expnumb,]],[tries[0:expnumb,]], [chosens[0:expnumb,]]])
# feat_d_arr = np.transpose(feat_d_arr)
print("""Experiment ran for %s times the max number of guesses is %s and the min is  %s, 
below is the four Dimensional array of data """ % (expnumb, np.amax(tries) , np.amin(tries)))
print(feat_d_arr.shape)

x_scaler = StandardScaler()
y_scaler = StandardScaler()
x= x_scaler.fit_transform(feat_d_arr[0:3,0:1800].reshape(1800,3))
y= y_scaler.fit_transform(feat_d_arr[3,0:1800].reshape(1800,1))


Model = MLPRegressor(hidden_layer_sizes=(10,5,1 ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='adaptive', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True, 
             random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, 
             validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10)

Model.fit(x,y)


pred = y_scaler.inverse_transform(Model.predict(feat_d_arr[0:3,1800:2000].reshape(200,3)))
real = feat_d_arr[3,1800:2000].reshape(200,1)
diff= real - pred

print("""The Neural Network Prediction is %s
      "and the real number is"""  % ( diff  ))
      
plt.plot(diff, 'ro')

plt.show()
